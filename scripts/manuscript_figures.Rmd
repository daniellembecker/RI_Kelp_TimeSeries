---
title: "manuscript_figures"
author: "daniellembecker"
date: "2024-05-23"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Use this script to use cleaned data and make plots for RI kelp data manuscript

# Load libraries 
```{r}
library(plyr)
library(kableExtra)
library(gt)
library(dplyr)
library(tigris)
library(MASS)
library(htmlwidgets)
library(car)
library(ggiraphExtra)
library(MuMIn)
library(lmerTest)
library(tidyverse)
library(lme4)
library(broom.mixed)
library(ggmap)
library(lubridate)
library(cowplot)
library(ggplot2)
library(PerformanceAnalytics)
library(reshape2)
library(viridis)
library(GGally)
library(corrplot)
library(patchwork)
library(broom)
library(knitr)
library(ggspatial)
library(rslp)
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
library(ggspatial)

```

# load cleaned dataframes

```{r}
# Set your directory path
directory <- "output/cleaned_data/"

# List files in the directory
files <- list.files(directory)

# Initialize an empty list to store data frames
data_frames <- list()

# Loop through each file
for (file in files) {
    # Read the file into a data frame
    # Adjust the read function according to your file type (e.g., read.csv, read.table)
    # Specify other parameters as needed (e.g., header = TRUE)
    file_path <- file.path(directory, file)
    df_name <- gsub("\\..*", "", file)  # Extract file name without extension
    assign(df_name, read.csv(file_path, stringsAsFactors = FALSE))
}

# Now, each file is a separate data frame with its own variable name

```


# Figure 1: organize data and make study site map of a) larger RI and NarrBay with Ft Weatherill and Kings Beach areas in boxes; b) zoom in of the Ft Weatherill box with specific transects as dots; c) zoom in of the Kings Beach box with specific transects as dots.
```{r}
# Create a dataframe with site coordinates
sites <- data.frame(
  Site = c("Fort Weatherill", "King's Beach"),
  Latitude = c(41.477, 41.452),  # Adjusted approximate values for the sites
  Longitude = c(-71.364, -71.326) # Adjusted approximate values for the sites
)

# Convert sites dataframe to an sf object
sites_sf <- st_as_sf(sites, coords = c("Longitude", "Latitude"), crs = 4326)

# Get Rhode Island state boundaries
ri_state <- states(cb = TRUE) %>% 
  filter(STUSPS == "RI") %>%
  st_transform(crs = 4326)

# Define the larger rectangle size (adjust as needed)
rect_size <- 0.02 

# Function to create rectangles around each site
create_rectangle <- function(site, rect_size) {
  lon <- st_coordinates(site)[1]
  lat <- st_coordinates(site)[2]
  st_as_sf(st_sfc(st_polygon(list(rbind(
    c(lon - rect_size, lat - rect_size), 
    c(lon - rect_size, lat + rect_size), 
    c(lon + rect_size, lat + rect_size), 
    c(lon + rect_size, lat - rect_size), 
    c(lon - rect_size, lat - rect_size)
  )))), crs = st_crs(site))
}

# Apply the create_rectangle function to each site
site_rectangles <- lapply(st_geometry(sites_sf), function(site) {
  create_rectangle(site, rect_size)
})

# Combine all rectangles into one sf object
site_rectangles <- do.call(rbind, site_rectangles)
st_crs(site_rectangles) <- st_crs(sites_sf) # Ensure CRS is set for combined rectangles

# Define label data
labels_tot <- data.frame(
  name = c("Narragansett\nBay", "Atlantic\nOcean"),
  lat = c(41.6, 41.3),
  lon = c(-71.35, -71.2)
)

# Plot panel A zoommed out RI and sites in rectangles
panelA <- ggplot() +
  geom_sf(data = ri_state, fill = "lightgray") + # State boundaries
  geom_sf(data = site_rectangles, color = "red2", fill = NA, size = 2) + # Add rectangles around sites
  geom_text(data = labels_tot, aes(x = lon, y = lat, label = name), size = 5, color = "black") + # Add labels
  coord_sf(xlim = c(-72, -71.0), ylim = c(41.1, 42.1), expand = FALSE) + # Zoom level
  annotation_scale(location = "bl", width_hint = 0.5) +
  annotation_north_arrow(location = "bl", which_north = "true", 
                         pad_x = unit(1.0, "in"), pad_y = unit(0.2, "in"),
                         style = north_arrow_fancy_orienteering) +
    # Change x and y axes names
  labs(x = "Longitude", y = "Latitude") +
  theme_classic() # Remove axes and background

panelA

# Save the plot to a file
ggsave("output/figures/figure_1A.png", plot = panelA, width = 8, height = 6)


# Filter transect data by site
transect_fw <- filter(site, Site == "Fort Wetherill")

# Adjust latitude values by subtracting 0.0013
transect_fw <- transect_fw %>%
  mutate(
    Start.Latitude = Start.Latitude - 0.0013
  )

# Define label data
labels <- data.frame(
  name = c("Fort\nWetherill"),
  lat = c(41.486),
  lon = c(-71.37)
)

# Plot panel B for fort wetherill transects
panelB <- ggplot() +
  geom_sf(data = ri_state, fill = "lightgray") + # State boundaries
  geom_point(data = transect_fw,
             aes(x = Start.Longitude, y = Start.Latitude),
             color = "black", fill = "red", size = 3, shape = 21) + # Add start points of transects
  annotation_scale(location = "bl", width_hint = 0.5) +
  annotation_north_arrow(location = "bl", which_north = "true", 
                         pad_x = unit(0.5, "in"), pad_y = unit(0.2, "in"),
                         style = north_arrow_fancy_orienteering) +
    geom_text(data = labels, aes(x = lon, y = lat, label = name), size = 5, color = "black") + # Add labels
  # Change x and y axes names
  labs(x = "Longitude", y = "Latitude") +
  theme_classic() + # Remove axes and background
  xlim(c(-71.40, -71.35)) + # Set longitude range
  ylim(c(41.46, 41.5))   # Set latitude range


panelB

# Save the plot to a file
ggsave("output/figures/figure_1B.png", plot = panelB, width = 8, height = 8)


# Filter transect data by site
transect_kb <- filter(site, Site == "King's Beach")

# Define label data
labels_kb <- data.frame(
  name = c("King's\nBeach"),
  lat = c(41.463),
  lon = c(-71.33)
)

# Adjust latitude values by subtracting 0.0011
transect_kb <- transect_kb %>%
  mutate(
    Start.Latitude = Start.Latitude - 0.0003
  )

# Plot panel C for kings beach transects
panelC <- ggplot() +
  geom_sf(data = ri_state, fill = "lightgray") + # State boundaries
  geom_point(data = transect_kb,
             aes(x = Start.Longitude, y = Start.Latitude),
             color = "black", fill = "red", size = 3, shape = 21) + # Add start points of transects
  annotation_scale(location = "bl", width_hint = 0.5) +
  annotation_north_arrow(location = "bl", which_north = "true", 
                         pad_x = unit(0.6, "in"), pad_y = unit(0.2, "in"),
                         style = north_arrow_fancy_orienteering) +
    geom_text(data = labels_kb, aes(x = lon, y = lat, label = name), size = 5, color = "black") + # Add labels
  # Change x and y axes names
  labs(x = "Longitude", y = "Latitude") +
  theme_classic() + # Remove axes and background
  xlim(c(-71.40, -71.3)) + # Set longitude range
  ylim(c(41.44, 41.5))   # Set latitude range


panelC

# Save the plot to a file
ggsave("output/figures/figure_1C.png", plot = panelC, width = 8, height = 6)


```

# Plot all three panels together using patchwork
```{r}

# Adjust width for individual plots
panelB <- panelB + theme(plot.margin = margin(r = 0))  # Remove right margin
panelC <- panelC + theme(plot.margin = margin(l = 0))  # Remove left margin

# Combine the plots with patchwork
combined_plot <- (panelA | (panelB / panelC)) +
  plot_annotation(tag_levels = 'A') + 
  theme(plot.tag = element_text(size = 20, face = "bold"));combined_plot

# Save the combined plot
ggsave("output/figures/figure_1.png", combined_plot, width = 12, height = 8, units = "in", dpi = 300)

```


# Figure 2: organize data to make fish biomass (g/m2) on y-axis and Kelp cover (%) figure
```{r}
# take kelp cover long and just extract data for sugar kelp 2019-2023
kelp.filt <- kelp %>%
        filter(SP_CODE == "SUGK")

# Convert the integer column to character
kelp.filt$CONTROL <- as.character(kelp.filt$CONTROL)
kelp.filt$TRANSECT <- as.character(kelp.filt$TRANSECT)

# remove control column, not needed
kelp.filt <- kelp.filt[ -c(5) ]

# Read the fish aggregated CSV file 2019-2023 and skip the first column
fish <- read.csv("data/kelp_timeseries_data/fish_Aggregated.csv") 

# remove Xcolumn, not needed
fish <- fish[ -c(1) ]

# Remove "KB", "FW", and space, keep only numbers
fish.filt <- fish %>%
  mutate(TRANSECT = gsub("KB |FW ", "", TRANSECT))

# Convert the integer column to character
fish.filt$TRANSECT <- as.character(fish.filt$TRANSECT)

# Rename fort weatherill
fish.filt$SITE[fish.filt$SITE == "Kings Beach"] <- "King's Beach"

# remove control column, not needed
fish.filt <- fish.filt[ -c(5) ]

# Assuming you want to join by the 'transect' column
merged.dat.cover <- left_join(fish.filt, kelp.filt)


```


# Make Figure 2 and run statistical analysis
```{r}
# Aggregate the data by year, site, and transect and compute mean values
aggregated_data_cover <- merged.dat.cover %>%
  group_by(YEAR, SITE, TRANSECT) %>%
  summarize(mean_fish_biomass = mean(Fish.Biomass..g.m2., na.rm = TRUE),
            mean_kelp_cover = mean(COVER, na.rm = TRUE)) %>%
  ungroup()

# Filter dataframe for six top fish biomass above 150
filt_data <- aggregated_data_cover %>%
  filter(mean_fish_biomass > 150)

# Make biomass a percent so * 100
aggregated_data_cover$mean_kelp_cover <- aggregated_data_cover$mean_kelp_cover * 100

# Fit the linear mixed effects model
lm_model <- lmer(mean_fish_biomass ~ mean_kelp_cover + SITE + (1 | SITE/YEAR), data = aggregated_data_cover)
#check normality
qqPlot(residuals(lm_model)) #slightly non normal values, log transform to improve

# Fit the linear mixed effects model with log transformation
lmm_model <- lmer(log(mean_fish_biomass + 1.1) ~ log(mean_kelp_cover + 1.1) + SITE + (1 | SITE/YEAR), data = aggregated_data_cover)
#check normality
qqPlot(residuals(lmm_model)) #improved to normal

# Summarize the model
lmm_summary <- summary(lmm_model)
lmm_tidy <- tidy(lmm_model)

# Calculate R-squared for the mixed model
r_squared <- r.squaredGLMM(lmm_model)

# Extract marginal and conditional R-squared
marginal_r2 <- round(r_squared[1], 2)
conditional_r2 <- round(r_squared[2], 2)

# Extract the p-value for the kelp biomass coefficient
p_value_kelp_cover <- lmm_summary$coefficients["log(mean_kelp_cover + 1.1)", "Pr(>|t|)"]

# Create scatter plot
figure.2 <- ggplot(aggregated_data_cover, aes(x = log(mean_kelp_cover + 1.1), y = log(mean_fish_biomass + 1.1))) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, formula = y ~ x, color = "blue") +
  
  # R-squared values
  annotate("text", x = Inf, y = Inf, 
           label = paste0("Marginal R^2 = ", marginal_r2, "\nConditional R^2 = ", conditional_r2), 
           hjust = 1.1, vjust = 1.1, size = 4) +
  
  # p-value
  annotate("text", x = Inf, y = -Inf, 
           label = paste0("p = ", format(p_value_kelp_cover, scientific = FALSE, digits = 2)), 
           hjust = 1.3, vjust = -38.5, size = 4) +
  
  labs(x = "Log Kelp cover (%)", y = "Log Fish biomass (g/m2)",
       title = "Fish Biomass vs Kelp Cover") +
  theme_classic() +
  theme(plot.margin = margin(t = 10, r = 30, b = 10, l = 10, unit = "pt")) +
  coord_cartesian(clip = 'off');figure.2

# Save the plot to a file
ggsave("output/figures/figure_2.png", plot = figure.2, width = 8, height = 6)
```


# Figure 3: organize and calculate kelp biomass data to make fish biomass/kelp biomass (g/m2) linear regression figure
```{r}
# read in quad data with filtered for just kelp
quad.filt <- QUAD %>%
        filter(SP_CODE == "SUGK")

# remove control column and two last columns, not needed
quad.filt <- quad.filt[ -c(13:14) ] 
quad.filt <- quad.filt[ -c(8) ] 
quad.filt <- quad.filt[ -c(5:6) ] 

# I noticed that 06/30/23 dates were accidentally labeled 06/30/29
# Replace "29" with "23" in the DATE column
quad.filt$DATE <- sub("29$", "23", quad.filt$DATE)

# Convert DATE to Date format
quad.filt$DATE <- as.Date(quad.filt$DATE, format = "%m/%d/%y")

# Convert Date format to "YYYY-MM-DD"
quad.filt$DATE <- format(quad.filt$DATE, "%Y-%m-%d")

# combine quad data with morph data to calculate kelp biomass

#load in morph data and select for SUGK
morph.filt <- morph %>%
        filter(SP_CODE == "SL")

#rename SL to SUGK
morph.filt$SP_CODE[morph.filt$SP_CODE == "SL"] <- "SUGK"

# Convert the integer column to character
morph.filt$TRANSECT <- as.character(morph.filt$TRANSECT)

# merge morph filt and quad.filt to calculate biomass
merge.morph.quad <- left_join(morph.filt, quad.filt)

#calculate kelp biomass
# To get wet weight in grams (biomass) you use the equation: y=0.00421*x^1.951 where x is kelp blade + stipe length.
# Calculate the sum of blade length and stipe length
merge.morph.quad$sum_length <- merge.morph.quad$BLADE_LENGTH_CM + merge.morph.quad$STIPE_LENGTH_CM

# Define a function to calculate kelp biomass
calculate_kelp_biomass <- function(x) {
  y <- 0.00421 * x^1.951
  return(y)
}

# Calculate kelp biomass using the sum of blade length and stipe length
merge.morph.quad$kelp_biomass <- calculate_kelp_biomass(merge.morph.quad$sum_length)

# Remove the intermediate columns if no longer needed
merge.morph.quad$kelp_blade_length <- NULL
merge.morph.quad$sum_length <- NULL

# Replace NA values with 0
merge.morph.quad$kelp_biomass <- ifelse(is.na(merge.morph.quad$kelp_biomass), 0, merge.morph.quad$kelp_biomass)

# Sum kelp biomass at the transect level
morph.filt <- merge.morph.quad %>%
  group_by(TRANSECT, YEAR, SITE) %>%
  summarize(total_kelp_biomass = sum(kelp_biomass))

# Divide by 6 quadrats for correct g/m2 calculation
morph.filt$average_kelp_biomass <- morph.filt$total_kelp_biomass / 6

# Merge fish and morph data
merged.dat.morph <- left_join(morph.filt, fish.filt)

```


# Make figure 3 fish biomass x kelp biomass and run statistical analysis
```{r}
# Aggregate the data by year, site, and transect and compute mean values
aggregated.data.morph <- merged.dat.morph %>%
  group_by(YEAR, SITE, TRANSECT) %>%
  summarize(mean_fish_biomass = mean(Fish.Biomass..g.m2., na.rm = TRUE),
            mean_kelp_biomass = mean(average_kelp_biomass, na.rm = TRUE)) %>%
  ungroup()

# Fit the linear mixed effects model
lmm_model <- lmer(mean_fish_biomass ~ mean_kelp_biomass + SITE + (1 | SITE/YEAR), data = aggregated.data.morph)
#check normality
qqPlot(residuals(lmm_model)) #slightly non normal values, log transform to improve

# Fit the linear mixed effects model with log transformation
lmm_model <- lmer(log(mean_fish_biomass + 1.1) ~ log(mean_kelp_biomass + 1.1) + SITE + (1 | SITE/YEAR), data = aggregated.data.morph)
#check normality
qqPlot(residuals(lmm_model)) #improved to normal

# Identify the outliers
outliers <- c(45, 37, 25, 33, 37, 22)

# remove outliers
data_clean <- aggregated.data.morph[-outliers, ]

# rerun model with log and without outliers
lmm_model <- lmer(log(mean_fish_biomass + 1.1) ~ log(mean_kelp_biomass + 1.1) * YEAR + (1 | SITE), data = data_clean)
#check normality
qqPlot(residuals(lmm_model)) #improved to normal

# Summarize the model
lmm_summary <- summary(lmm_model)
lmm_tidy <- tidy(lmm_model)

# Export to CSV file
write.csv(lmm_tidy, "output/lmm_model_results.csv", row.names = FALSE)


# Calculate R-squared for the mixed model
r_squared <- r.squaredGLMM(lmm_model)

# Extract marginal and conditional R-squared
marginal_r2 <- round(r_squared[1], 2)
conditional_r2 <- round(r_squared[2], 2)

# Extract the p-value for the kelp biomass coefficient
p_value_kelp_biomass <- lmm_summary$coefficients["log(mean_kelp_biomass + 1.1)", "Pr(>|t|)"]


# Create scatter plot
figure.3 <- ggplot(aggregated.data.morph, aes(x = log(mean_kelp_biomass + 1.1), y = log(mean_fish_biomass + 1.1))) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, formula = y ~ x, color = "blue") +
  
  # R-squared values
  annotate("text", x = Inf, y = Inf, 
           label = paste0("Marginal R^2 = ", marginal_r2, "\nConditional R^2 = ", conditional_r2), 
           hjust = 1.1, vjust = 1.1, size = 4) +
  
  # p-value
  annotate("text", x = Inf, y = -Inf, 
           label = paste0("p = ", format(p_value_kelp_biomass, scientific = FALSE, digits = 2)), 
           hjust = 1.3, vjust = -38.5, size = 4) +
  
  labs(x = expression("Log Kelp Biomass (g/" ~ m^2 ~ ")"), y = expression("Log Fish Biomass (g/" ~ m^2 ~ ")")) +
  theme_classic() +
  theme(plot.margin = margin(t = 10, r = 30, b = 10, l = 10, unit = "pt")) +
  coord_cartesian(clip = 'off') +
  theme(
    axis.title.x = element_text(size = 18),
    axis.title.y = element_text(size = 18),
    axis.text.x = element_text(size = 18),
    axis.text.y = element_text(size = 18));figure.3


# Save the plot to a file
ggsave("output/figures/figure_3.png", plot = figure.3, width = 8, height = 6)
```

# Make kelp biomass time series (a) 
```{r}
# Function to calculate standard error
std_error <- function(x) {
  sd(x, na.rm = TRUE) / sqrt(length(na.omit(x)))
}

# Aggregate the data by year and site and compute mean values and standard error
aggregated.kelp.morph <- morph.filt %>%
  group_by(YEAR, SITE) %>%
  summarize(
    mean_kelp_biomass = mean(average_kelp_biomass, na.rm = TRUE),
    se_kelp_biomass = std_error(average_kelp_biomass)
  ) %>%
  ungroup()

# Transform mean kelp biomass and standard error to log scale
aggregated.kelp.morph <- aggregated.kelp.morph %>%
  mutate(
    log_mean_kelp_biomass = log(mean_kelp_biomass + 1.1),
    log_se_kelp_biomass = log(mean_kelp_biomass + 1.1 + se_kelp_biomass) - log(mean_kelp_biomass + 1.1)
  )

# Define shapes for sites
shape_values <- c("Fort Wetherill" = 16, "King's Beach" = 17) # Circle for Fort Wetherill, Triangle for King's Beach

# Time series plot for kelp biomass with standard error bars from 2016-2023
kelp.timeseries.2016 <- ggplot(aggregated.kelp.morph, aes(x = YEAR, y = log_mean_kelp_biomass, shape = SITE)) +
  geom_line(aes(group = SITE), color = "black") +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = log_mean_kelp_biomass - log_se_kelp_biomass, 
                    ymax = log_mean_kelp_biomass + log_se_kelp_biomass), 
                width = 0.2) +
  scale_shape_manual(values = shape_values) +
  labs(x = "Year", y = expression("Log Mean Kelp Biomass (g/" ~ m^2 ~ ")"), shape = "Site") +
  theme_bw() +
  scale_x_continuous(breaks = unique(aggregated.kelp.morph$YEAR)) +
  theme(
    axis.title.x = element_text(size = 18),
    axis.title.y = element_text(size = 18),
    axis.text.x = element_text(size = 18),
    axis.text.y = element_text(size = 18),
    legend.text = element_text(size = 16),
    legend.title = element_text(size = 18)
  );kelp.timeseries.2016

# Save the plot to a file
ggsave("output/figures/kelp_timeseries_2016.png", plot = kelp.timeseries.2016, width = 8, height = 6)

# Filter for the years 2019-2023
filtered_data <- aggregated.kelp.morph %>%
  filter(YEAR >= 2019 & YEAR <= 2023)

# Time series plot for kelp biomass with standard error bars for 2019-2023
kelp.timeseries.2019_2023 <- ggplot(filtered_data, aes(x = YEAR, y = log_mean_kelp_biomass, shape = SITE)) +
  geom_line(aes(group = SITE), color = "black") +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = log_mean_kelp_biomass - log_se_kelp_biomass, 
                    ymax = log_mean_kelp_biomass + log_se_kelp_biomass), 
                width = 0.2) +
  scale_shape_manual(values = shape_values) +
  labs(x = "Year", y = expression("Log Mean Kelp Biomass (g/" ~ m^2 ~ ")"), shape = "Site") +
  theme_bw() +
  theme(
    axis.title.x = element_text(size = 18),
    axis.title.y = element_text(size = 18),
    axis.text.x = element_text(size = 18),
    axis.text.y = element_text(size = 18),
    legend.text = element_text(size = 16),
    legend.title = element_text(size = 18)
  );kelp.timeseries.2019_2023

# Save the plot to a file
ggsave("output/figures/kelp_timeseries_2019.png", plot = kelp.timeseries.2019_2023, width = 8, height = 6)


```

# Rate of change (b) by site figure
```{r}
# Fit the linear model
lm_model <- lm(average_kelp_biomass ~ YEAR, data = morph.filt)
#check normality
qqPlot(residuals(lm_model)) #data is normal no need to transform

# Fit log transformed linear model
lm_model <- lm(log(average_kelp_biomass + 1.1) ~ YEAR, data = morph.filt)
#check normality
qqPlot(residuals(lm_model)) #data is normal no need to transform

# Convert YEAR to numeric (if necessary)
morph.filt$YEAR <- as.numeric(as.character(morph.filt$YEAR))

# Define shapes for sites
shape_values <- c("Fort Wetherill" = 16, "King's Beach" = 17)  # Circle for Fort Wetherill, Triangle for King's Beach

# Fit linear regression models for each SITE separately
slope_results <- morph.filt %>%
  mutate(log_avg_kelp_biomass = log(average_kelp_biomass + 1.1)) %>%
  group_by(SITE) %>%
  summarize(
    mean_slope = coef(lm(log_avg_kelp_biomass ~ YEAR))[2],  # Mean slope
    se_slope = summary(lm(log_avg_kelp_biomass ~ YEAR))$coefficients[2, "Std. Error"],  # Standard error of slope
    mean_log_avg_kelp_biomass = mean(log_avg_kelp_biomass)  # Mean log average kelp biomass
  )

# Calculate rate of change per year
slope_results <- slope_results %>%
  mutate(
    rate_of_change_per_year = mean_slope / mean_log_avg_kelp_biomass,  # Rate of change per year
    se_rate_of_change = se_slope / mean_log_avg_kelp_biomass  # Standard error of rate of change per year
  )

# Plotting the mean rates of change with error bars (standard error horizontally)
rate_of_change <- ggplot(slope_results, aes(x = rate_of_change_per_year, y = mean_log_avg_kelp_biomass, shape = SITE)) +
  geom_point(size = 3) +
  geom_errorbarh(aes(xmin = rate_of_change_per_year - se_rate_of_change, xmax = rate_of_change_per_year + se_rate_of_change), height = 0.2) +
  labs(
    x = expression("Rate of Change ("~yr^-1 ~")"),
    y = expression("Log Mean Kelp Biomass (g/"~m^2~")"), shape = "Site") +
  theme_bw() +
  scale_shape_manual(values = shape_values, guide = guide_legend(title = "Site")) +   # Use shape values and customize legend
  theme(
    axis.title.x = element_text(size = 18),
    axis.title.y = element_text(size = 18),
    axis.text.x = element_text(size = 18),
    axis.text.y = element_text(size = 18),
    legend.text = element_text(size = 16),
    legend.title = element_text(size = 18));rate_of_change


```


# Plot two panels together using patchwork
```{r}
# Combine the plots with patchwork for all years of kelp and rate of change
kelp.rate.2016 <- kelp.timeseries.2016 | rate_of_change +
  plot_annotation(tag_levels = 'A') + 
  theme(plot.tag = element_text(size = 20, face = "bold"));kelp.rate.2016

# Save the combined plot
ggsave("output/figures/kelp.2016.rate.png", kelp.rate.2016, width = 20, height = 8, units = "in", dpi = 300)

# Combine the plots with patchwork for all years of kelp and rate of change
kelp.rate.2019 <- kelp.timeseries.2019_2023 | rate_of_change +
  plot_annotation(tag_levels = 'A') + 
  theme(plot.tag = element_text(size = 20, face = "bold"));kelp.rate.2019

# Save the combined plot
ggsave("output/figures/kelp.2019.rate.png", kelp.rate.2019, width = 20, height = 8, units = "in", dpi = 300)

```


# Organize rugosity data and make linear regression figure for fish biomass and rugosity
```{r}
# Calculate mean rugosity complexity scores across depths for each transect, grouped by site and year
mean_rugosity <- rugosity %>%
  group_by(SITE, YEAR, TRANSECT) %>%
  summarize(mean_rugosity = mean(c(X0M, X4M, X8M, X12M, X16M, X20M, X24M, X28M, X32M, X36M, X40M), na.rm = TRUE))

# change transect from integer to chr
mean_rugosity$TRANSECT <- as.character(mean_rugosity$TRANSECT)

# Left jon fish and rugosity data
merged.dat.rug <- left_join(mean_rugosity, fish.filt)

```


# Make figure 4 and run statistical analysis
```{r}
# Aggregate the data by year, site, and transect and compute mean values
aggregated.data.rug <- merged.dat.rug %>%
  group_by(YEAR, SITE, TRANSECT) %>%
  summarize(mean_fish_biomass = mean(Fish.Biomass..g.m2., na.rm = TRUE),
            mean_rugosity = mean(mean_rugosity, na.rm = TRUE)) %>%
  ungroup()

# Fit the linear mixed effects model
lmm_model <- lmer(mean_fish_biomass ~ mean_rugosity + SITE + (1 | SITE/YEAR), data = aggregated.data.rug)
#check normality
qqPlot(residuals(lmm_model)) #data is normal no need to transform

# Fit the linear mixed effects model with log transformation
lmm_model <- lmer(log(mean_fish_biomass + 1.1) ~ log(mean_rugosity + 1.1) + SITE + (1 | SITE/YEAR), data = aggregated.data.rug)
#check normality
qqPlot(residuals(lmm_model)) #improved to normal

# Identify the outliers
outliers <- c(25, 37, 24, 35)

# remove outliers
data_clean.rug <- aggregated.data.rug[-outliers, ]

# rerun model with log and without outliers
lmm_model <- lmer(log(mean_fish_biomass + 1.1) ~ log(mean_rugosity + 1.1) + SITE + (1 | SITE/YEAR), data = data_clean.rug)
#check normality
qqPlot(residuals(lmm_model)) #improved to normal

# Summarize the model
lmm_summary <- summary(lmm_model)
lmm_tidy <- tidy(lmm_model)

# Calculate R-squared for the mixed model
r_squared <- r.squaredGLMM(lmm_model)

# Extract marginal and conditional R-squared
marginal_r2 <- round(r_squared[1], 2)
conditional_r2 <- round(r_squared[2], 2)

# Extract the p-value for the rugosity
p_value_rugosity <- lmm_summary$coefficients["log(mean_rugosity + 1.1)", "Pr(>|t|)"]

#create scatter plot
figure.4 <- ggplot(aggregated.data.rug, aes(x = log(mean_rugosity + 1.1), y = log(mean_fish_biomass + 1.1))) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, formula = y ~ x, color = "blue") +
  
  # R-squared values
  annotate("text", x = Inf, y = Inf, 
           label = paste0("Marginal R^2 = ", marginal_r2, "\nConditional R^2 = ", conditional_r2), 
           hjust = 1.1, vjust = 1.1, size = 4) +
  
  # p-value
  annotate("text", x = Inf, y = -Inf, 
           label = paste0("p = ", format(p_value_rugosity, scientific = FALSE, digits = 2)), 
           hjust = 1.3, vjust = -38.5, size = 4) +
  
  labs(x = "Rugosity Complexity", y = "Fish biomass (g/m2)",
       title = "Fish Biomass vs Rugosity Complexity") +
  theme_classic() +
  theme(plot.margin = margin(t = 10, r = 30, b = 10, l = 10, unit = "pt")) +
  coord_cartesian(clip = 'off');figure.4


# Save the plot to a file
ggsave("output/figures/figure_4.png", plot = figure.4, width = 8, height = 6)
```


# Filter quad data for all inverts and use to correlate to fish biomass
```{r}
#invert.filt <- 


```



# Figure 5: Correlation analysis between fish biomass (g/m2), kelp biomass (g/m2), kelp cover, rugosity, temperature in ggplot 
# combine all dataframes
```{r}
# left join can only combine two at a time
# combing kelp cover and fish biomass
master.dat1 <- left_join(kelp.filt, fish.filt)

#combine rugosity and kelp biomass
master.dat2 <- left_join(mean_rugosity, morph.filt)

# combine for final dataframe
master.dat <- left_join(master.dat1, master.dat2)

# output to .csv
write.csv(master.dat, "output/cleaned_data/master_output_dataframe.csv")

#select necessary columns
all.params.data <- master.dat %>% dplyr::select("YEAR", "SITE", "COVER", "Fish.Biomass..g.m2.", "mean_rugosity", "average_kelp_biomass")

#rename various columns in data frame
names(all.params.data)[3] <- "Kelp Cover (%)"
names(all.params.data)[4] <- "Fish Biomass (g/cm2)"
names(all.params.data)[5] <- "Rugosity"
names(all.params.data)[6] <- "Kelp Biomass (g/cm2)"

#reorder columns to show biomass by eachother
all.params.data <- all.params.data[, c(1,2, 4, 6, 5, 3)]

view(all.params.data)

# Check for missing values
any_missing <- any(is.na(all.params.data))
if (any_missing) {
  # Handle missing values
  all.params.data <- na.omit(all.params.data)
}

# Select the relevant columns
selected_columns <- all.params.data[, c("Fish Biomass (g/cm2)", "Kelp Biomass (g/cm2)", "Rugosity", "Kelp Cover (%)")]

# Calculate the Spearman correlation matrix
cormat <- round(cor(selected_columns, method = "spearman", use = "complete.obs"), 4)
head(cormat)

#melt the correlation matrix means it reassembles data frame to be more effective to complete corr matrix
#to long format
melted_cormat <- melt(cormat)
head(melted_cormat)

#visulaize the correlation matrix in general
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile()

# Get lower and upper triangle of the correlation matrix
#Note that, a correlation matrix has redundant information. We’ll use the functions below to set half of it to NA
get_lower_tri<-function(cormat){
  cormat[upper.tri(cormat)] <- NA
  return(cormat)
}
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
  cormat[lower.tri(cormat)]<- NA
  return(cormat)
}

#apply upper tri calculation to graphc
upper_tri <- get_upper_tri(cormat)
upper_tri

#melt the correlation matrix
#melt the correlation data and drop the rows with NA values 
melted_cormat <- melt(upper_tri, na.rm = TRUE)

#heatmap of correlation matrix
#negative correlations are in purple color and positive correlations in red
#scale_fill_gradient2 is used with the argument limit = c(-1,1) as correlation coefficients range from -1 to 1
#coord_fixed() : this function ensures that one unit on the x-axis is the same length as one unit on the y-axis
ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
  geom_tile(color = "white")+
  scale_fill_gradient2(low = "midnightblue", high = "firebrick4", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman's\nCorrelation") +
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1))+
  coord_fixed()



#edit the number of sig figs listed in the value column
melted_cormat <- melted_cormat %>% mutate_at(vars(starts_with("value")), funs(round(., 2)))

# Create a ggheatmap with basic characteristics, etc. 
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
  geom_tile(color = "white")+
  scale_fill_gradient2(low = "firebrick3", mid = "white", high = "dodgerblue3", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman's\nCorrelation") +
  theme_minimal()+ # minimal theme
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1))+
  coord_fixed()


# Print the heatmap
print(ggheatmap)


# Check for normality
shapiro.test(all.params.data$`Kelp Cover (%)`)
shapiro.test(all.params.data$`Fish Biomass (g/cm2)`) 
shapiro.test(all.params.data$Rugosity)
shapiro.test(all.params.data$`Kelp Biomass (g/cm2)`)

# data is not normal so move forward using aa spearmans rank correlation test

## Calculate p-values
p_values <- cor.mtest(selected_columns, method = "spearman")$p

## Convert the correlation matrix to a data frame
cormat_df <- reshape2::melt(cormat)

## Add p-values to the data frame
cormat_df$p_value <- p_values[cbind(cormat_df$Var1, cormat_df$Var2)]

# Define the custom apply_rules function
apply_rules <- function(p_values, rules = c(0.001, 0.01, 0.05), symbols = c("***", "**", "*")) {
  result <- rep("", length(p_values))
  for (i in seq_along(rules)) {
    result[p_values < rules[i]] <- symbols[i]
  }
  return(result)
}

## Create a new column to display stars based on p-values
cormat_df$sig <- apply_rules(cormat_df$p_value, rules = c(0.001, 0.01, 0.05), symbols = c("***", "**", "*"))

# Remove repeating rows
corузыdated_cormat_df <- cormat_df[!duplicated(cormat_df[, c("Var1", "Var2")]), ]

# Replace non-significant p-узыdues with "ns"
cormat_df$sig[cormat_df$p_value > 0.05] <- "ns"

# Print the modified data
print(cormat_df)

# Add correlation coefficients to the heatmap
ggheatmap +
  geom_text(data = cormat_df, aes(Var1, Var2, label = ifelse(Var1 == Var2, value, 
                                                             ifelse(sig == "", paste0(value, "\nns"), 
                                                             ifelse(duplicated(paste0(value, "\n", sig)), "", paste0(value, "\n", sig))))), 
            color = "black", size = 6) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.x = element_text(size = 18, face="bold", color="black"),
        axis.text.y = element_text(size = 18, face="bold", color="black"),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.ticks = element_blank(),
        legend.justification = c(0.8, 0),
        legend.title = element_text(size = 18, face="bold", color="black"),
        legend.text = element_text(size = 20, face="bold", color="black"),
        legend.position = c(0.48, 0.75),
        legend.direction = "horizontal") +
  guides(fill = guide_colorbar(barwidth = 12, barheight = 2,
                               title.position = "top", title.hjust = 0.5, title.vjust = 1.0))



ggsave(filename = "output/figures/figure_5.png", device = "png", width = 10, height = 10)

```

# Multiple regression between fish biomass (g/m2), kelp biomass (g/m2), kelp cover, rugosity, temperature in ggplot 
# combine all dataframes
```{r}
# Rename columns to remove spaces and special characters
names(all.params.data) <- c("YEAR", "SITE", "Fish_Biomass", "Rugosity", "Kelp_Cover", "Kelp_Biomass")

# was getting an error: qr.default(X, tol = tol, LAPACK = FALSE) when running model below which indicates that there are still problematic values (NA, NaN, or Inf) in the data used for the model fitting

# Check for zero or negative values
zero_or_negative <- sapply(all.params.data[, c("Fish_Biomass", "Rugosity", "Kelp_Biomass", "Kelp_Cover")], function(x) sum(x <= 0))
zero_or_negative

# Remove rows with zero or negative values in relevant columns
all.params.data <- all.params.data[all.params.data$Fish_Biomass > 0 & 
                                   all.params.data$Rugosity > 0 & 
                                   all.params.data$Kelp_Biomass > 0 & 
                                   all.params.data$Kelp_Cover > 0, ]

# Fit a multiple regression model
fit1 <- lm(log(Fish_Biomass + 1.1) ~ log(Rugosity + 1.1) * log(Kelp_Biomass + 1.1) * log(Kelp_Cover + 1.1), data = all.params.data)
summary(fit1)

# Diagnostic plots for the regression model
par(mfrow=c(2,2))
plot(fit1)

# Produce added multivariable plots
av_plots <- avPlots(fit1)

#The x-axis displays a single predictor variable and the y-axis displays the response variable.
#The blue line shows the association between the predictor variable and the response variable, while holding the value of all other predictor variables constant.
#The points that are labelled in each plot represent the 2 observations with the largest residuals and the 2 observations with the largest partial leverage.

#view results of model
summary_text1 <- capture.output(summary(fit1))
writeLines(summary_text1, "output/model.result.tables/rugosity.included/summary_original.model.txt")

```


# Try another type of multiple regession plot
```{r}
#fit multiple linear regression model WITH SITE AND YEAR
fit2 <- lm(Fish_Biomass ~ SITE*YEAR, data = all.params.data)
summary(fit2)

#view results of model
summary_text2 <- capture.output(summary(fit2))
writeLines(summary_text2, "output/model.result.tables/rugosity.included/summary_model_site_year_fixed_fishbiomass.txt")


# Fit the mixed-effects model
fit3 <- lmer(log(Fish_Biomass) ~ log(Rugosity) * log(Kelp_Biomass) * log(Kelp_Cover) + 
              (1 | SITE) + (1 | YEAR), data = all.params.data)
summary(fit3)

#view results of model
summary_text3 <- capture.output(summary(fit3))
writeLines(summary_text3, "output/model.result.tables/rugosity.included/summary_model_site_year_random.txt")

# site and year no significant interaction or significant main effects

# run with just site as random effect
# Fit the mixed-effects model
fit4 <- lmer(log(Fish_Biomass + 1.1) ~ log(Rugosity + 1.1) * log(Kelp_Biomass + 1.1) * log(Kelp_Cover + 1.1) + 
              (1 | SITE), data = all.params.data)
summary(fit4)

#view results of model
summary_text4 <- capture.output(summary(fit4))
writeLines(summary_text4, "output/model.result.tables/rugosity.included/summary_model_site_random.txt")

# site and year no significant main effects

# run with just year as random effect
# Fit the mixed-effects model
fit5 <- lmer(log(Fish_Biomass + 1.1) ~ log(Rugosity + 1.1) * log(Kelp_Biomass + 1.1) * log(Kelp_Cover + 1.1) + 
              (1 | YEAR), data = all.params.data)
summary(fit5)

#view results of model
summary_text5 <- capture.output(summary(fit5))
writeLines(summary_text5, "output/model.result.tables/rugosity.included/summary_model_year_random.txt")

#year is significantly different for kelp cover

```


# Run all above models without rugosity
```{r}

# Fit a multiple regression model
fit6 <- lm(log(Fish_Biomass + 1.1) ~ log(Kelp_Biomass + 1.1) * log(Kelp_Cover + 1.1), data = all.params.data)
summary(fit6)

#view results of model
summary_text6 <- capture.output(summary(fit6))
writeLines(summary_text6, "output/model.result.tables/rugosity.not.included/summary_original.model.txt")

#no sig diff effects

# Fit the mixed-effects model
fit7 <- lmer(log(Fish_Biomass) ~ log(Kelp_Biomass) * log(Kelp_Cover) + (1 | SITE) + (1 | YEAR), data = all.params.data)
summary(fit7)

#view results of model
summary_text7 <- capture.output(summary(fit7))
writeLines(summary_text7, "output/model.result.tables/rugosity.not.included/summary_model_site_year_random.txt")

# site and year no significant interaction or significant main effects

# run with just site as random effect
# Fit the mixed-effects model
fit8 <- lmer(log(Fish_Biomass + 1.1) ~ log(Kelp_Biomass + 1.1) * log(Kelp_Cover + 1.1) + (1 | SITE), data = all.params.data)
summary(fit8)

#view results of model
summary_text8 <- capture.output(summary(fit8))
writeLines(summary_text8, "output/model.result.tables/rugosity.not.included/summary_model_site_random.txt")

# site not sig different

# run with just year as random effect
# Fit the mixed-effects model
fit9 <- lmer(log(Fish_Biomass + 1.1) ~  log(Kelp_Biomass + 1.1) * log(Kelp_Cover + 1.1) + (1 | YEAR), data = all.params.data)
summary(fit9)

#view results of model
summary_text9 <- capture.output(summary(fit9))
writeLines(summary_text9, "output/model.result.tables/rugosity.not.included/summary_model_year_random.txt")

#year is not sig different


# site not sig different
```

# Run model for fish_biomass ~ kelp_biomass * year (randomize site)
```{r}
# Fit the mixed-effects model
fit10 <- lmer(log(Fish_Biomass + 1.1) ~ log(Kelp_Biomass + 1.1) * YEAR + (1 | SITE), data = all.params.data)
summary(fit10)

# Example: Standardizing numeric variables in your dataset
all.params.data$Kelp_Biomass_standardized <- scale(all.params.data$Kelp_Biomass)
all.params.data$YEAR_standardized <- scale(all.params.data$YEAR)

# Fit the model with standardized predictors
fit10 <- lmer(log(Fish_Biomass + 1.1) ~ log(Kelp_Biomass_standardized + 1.1) * YEAR_standardized + (1 | SITE), data = all.params.data)
summary(fit10)

#view results of model
summary_text10 <- capture.output(summary(fit10))
writeLines(summary_text9, "output/model.result.tables/rugosity.not.included/summary_model_year_random.txt")

```


# Run model on temperature by date between two sites 
```{r}
# Add a 'Site' column to each dataframe
FW_temperature$Site <- "FW"
KB_temperature$Site <- "KB"

# Combine data frames
temperature_data <- rbind(FW_temperature, KB_temperature)

# Check normality for each site
shapiro.test(temperature_data$Temp[temperature_data$Site == "KB"])
shapiro.test(temperature_data$Temp[temperature_data$Site == "FW"])

# data not normal

# Perform Mann-Whitney U Test for site
mann_whitney_test <- wilcox.test(Temp ~ Site, data = temperature_data, exact = FALSE)
print(mann_whitney_test)

# Convert Date column to Date class
temperature_data$Date <- as.Date(temperature_data$Date, format = "%m/%d/%y")

# Extract Year and Month
temperature_data <- temperature_data %>%
  mutate(
    Year = year(Date),
    Month = month(Date)
  )

# Calculate monthly averages
monthly_averages <- temperature_data %>%
  group_by(Year, Month, Site) %>%
  summarize(AverageTemp = mean(Temp), .groups = 'drop')

# Fit linear model
model <- lm(log(AverageTemp +1.1) ~ Month + Year + Site, data = monthly_averages)

#check normality
qqPlot(residuals(model)) #improved to normal

#not normal

# Remove specific outliers
cleaned_data <- monthly_averages[-c(95, 96), ]

# Refit the model without outliers
cleaned_model <- lm(log(AverageTemp + 1.1) ~ Month + Year + Site, data = cleaned_data)
qqPlot(residuals(cleaned_model))
summary(cleaned_model)

#month is sig different but year and site are not

```

# Make line plot for temperature time series by site per month
```{r}
# Calculate average temperature per month and site
avg_temp <- temperature_data %>%
  mutate(MonthAbbrev = month.abb[Month]) %>%  # Add month abbreviations
  group_by(MonthAbbrev, Site) %>%
  summarize(avg_temp = mean(Temp))

# Map site codes to full names
avg_temp$Site <- ifelse(avg_temp$Site == "FW", "Fort Wetherill", "King's Beach")

# Plotting average temperature by site as lines and points per month
temperature_plot <- ggplot(avg_temp, aes(x = MonthAbbrev, y = avg_temp, color = Site, group = Site)) +
  geom_line(size = 1.5) +  # Lines for average temperature by site
  geom_point(size = 3) +  # Points for mean values by site
  labs(x = "Month", y = expression("Average Temperature (°C)"), color = "Site") +
  scale_color_manual(values = c("Fort Wetherill" = "grey", "King's Beach" = "black")) +  # Custom colors
  theme_bw()+
    theme(
    axis.title.x = element_text(size = 18),
    axis.title.y = element_text(size = 18),
    axis.text.x = element_text(size = 18),
    axis.text.y = element_text(size = 18),
    legend.text = element_text(size = 16),
    legend.title = element_text(size = 18));temperature_plot

# Save the plot to a file
ggsave("output/figures/temp.plot.png", plot = temperature_plot, width = 20, height = 10)
```


# Make a table for temperature values (monthly mean plus/minus one standard error) for each site (for supplement)
```{r}
# Calculate monthly mean and standard error
summary_table <- temperature_data %>%
  group_by(Site, Month) %>%
  summarize(
    MeanTemp = mean(Temp),
    StdDev = sd(Temp),
    N = n(),
    StdError = StdDev / sqrt(N)
  ) %>%
  mutate(
    MeanPlusSE = MeanTemp + StdError,
    MeanMinusSE = MeanTemp - StdError
  ) %>%
  ungroup() %>%
  dplyr::select(Site, Month, MeanTemp, MeanPlusSE, MeanMinusSE)

# Mapping month numbers to month names
month_names <- c("January", "February", "March", "April", "May", "June", 
                 "July", "August", "September", "October", "November", "December")

# Mapping site abbreviations to full names
site_names <- c("FW" = "Fort Wetherill", "KB" = "King's Beach")

# Replace numeric month values with month names
summary_table$Month <- month_names[summary_table$Month]

# Replace site abbreviations with full names
summary_table$Site <- site_names[summary_table$Site]

# Create a gt table
table_gt <- gt(summary_table) %>%
  tab_header(
    title = "Monthly Mean Temperatures by Site",
    subtitle = "Summary Table"
  ) %>%
  fmt_number(
    columns = vars(MeanTemp, MeanPlusSE, MeanMinusSE),
    decimals = 1
  ) %>%
  tab_style(
    style = list(
      cell_text(color = "black", weight = "bold")
    ),
    locations = cells_body()
  );table_gt

# Save as HTML
gtsave(table_gt, file = "output/temperature_table.html")

```
Temperature between sites is not significantly different 

	Wilcoxon rank sum test with continuity correction

data:  Temp by Site
W = 4273000, p-value = 0.9511
alternative hypothesis: true location shift is not equal to 0


Production to biomass ratios (P:B) for each fish species
```{r}

```






