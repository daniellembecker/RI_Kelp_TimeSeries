---
title: "manuscript_figures"
author: "daniellembecker"
date: "2024-05-23"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Use this script to use cleaned data and make plots for RI kelp data manuscript

# Load libraries 
```{r}
library(plyr)
library(dplyr)
library(tigris)
library(htmlwidgets)
library(car)
library(ggiraphExtra)
library(MuMIn)
library(lmerTest)
library(tidyverse)
library(lme4)
library(broom.mixed)
library(ggmap)
library(lubridate)
library(cowplot)
library(ggplot2)
library(PerformanceAnalytics)
library(reshape2)
library(viridis)
library(GGally)
library(corrplot)
library(patchwork)
library(broom)
library(ggspatial)
library(rslp)
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
library(ggspatial)

```

# load cleaned dataframes

```{r}
# Set your directory path
directory <- "output/cleaned_data/"

# List files in the directory
files <- list.files(directory)

# Initialize an empty list to store data frames
data_frames <- list()

# Loop through each file
for (file in files) {
    # Read the file into a data frame
    # Adjust the read function according to your file type (e.g., read.csv, read.table)
    # Specify other parameters as needed (e.g., header = TRUE)
    file_path <- file.path(directory, file)
    df_name <- gsub("\\..*", "", file)  # Extract file name without extension
    assign(df_name, read.csv(file_path, stringsAsFactors = FALSE))
}

# Now, each file is a separate data frame with its own variable name

```


# Figure 1: organize data and make study site map of a) larger RI and NarrBay with Ft Weatherill and Kings Beach areas in boxes; b) zoom in of the Ft Weatherill box with specific transects as dots; c) zoom in of the Kings Beach box with specific transects as dots.
```{r}
# Create a dataframe with site coordinates
sites <- data.frame(
  Site = c("Fort Weatherill", "King's Beach"),
  Latitude = c(41.477, 41.452),  # Adjusted approximate values for the sites
  Longitude = c(-71.364, -71.326) # Adjusted approximate values for the sites
)

# Convert sites dataframe to an sf object
sites_sf <- st_as_sf(sites, coords = c("Longitude", "Latitude"), crs = 4326)

# Get Rhode Island state boundaries
ri_state <- states(cb = TRUE) %>% 
  filter(STUSPS == "RI") %>%
  st_transform(crs = 4326)

# Define the larger rectangle size (adjust as needed)
rect_size <- 0.02 

# Function to create rectangles around each site
create_rectangle <- function(site, rect_size) {
  lon <- st_coordinates(site)[1]
  lat <- st_coordinates(site)[2]
  st_as_sf(st_sfc(st_polygon(list(rbind(
    c(lon - rect_size, lat - rect_size), 
    c(lon - rect_size, lat + rect_size), 
    c(lon + rect_size, lat + rect_size), 
    c(lon + rect_size, lat - rect_size), 
    c(lon - rect_size, lat - rect_size)
  )))), crs = st_crs(site))
}

# Apply the create_rectangle function to each site
site_rectangles <- lapply(st_geometry(sites_sf), function(site) {
  create_rectangle(site, rect_size)
})

# Combine all rectangles into one sf object
site_rectangles <- do.call(rbind, site_rectangles)
st_crs(site_rectangles) <- st_crs(sites_sf) # Ensure CRS is set for combined rectangles

# Define label data
labels_tot <- data.frame(
  name = c("Narragansett\nBay", "Atlantic\nOcean"),
  lat = c(41.6, 41.3),
  lon = c(-71.35, -71.2)
)

# Plot panel A zoommed out RI and sites in rectangles
panelA <- ggplot() +
  geom_sf(data = ri_state, fill = "lightgray") + # State boundaries
  geom_sf(data = site_rectangles, color = "red2", fill = NA, size = 2) + # Add rectangles around sites
  geom_text(data = labels_tot, aes(x = lon, y = lat, label = name), size = 5, color = "black") + # Add labels
  coord_sf(xlim = c(-72, -71.0), ylim = c(41.1, 42.1), expand = FALSE) + # Zoom level
  annotation_scale(location = "bl", width_hint = 0.5) +
  annotation_north_arrow(location = "bl", which_north = "true", 
                         pad_x = unit(1.0, "in"), pad_y = unit(0.2, "in"),
                         style = north_arrow_fancy_orienteering) +
    # Change x and y axes names
  labs(x = "Longitude", y = "Latitude") +
  theme_classic() # Remove axes and background

panelA

# Save the plot to a file
ggsave("output/figures/figure_1A.png", plot = panelA, width = 8, height = 6)


# Filter transect data by site
transect_fw <- filter(site, Site == "Fort Wetherill")

# Adjust latitude values by subtracting 0.0013
transect_fw <- transect_fw %>%
  mutate(
    Start.Latitude = Start.Latitude - 0.0013
  )

# Define label data
labels <- data.frame(
  name = c("Fort\nWetherill"),
  lat = c(41.486),
  lon = c(-71.37)
)

# Plot panel B for fort wetherill transects
panelB <- ggplot() +
  geom_sf(data = ri_state, fill = "lightgray") + # State boundaries
  geom_point(data = transect_fw,
             aes(x = Start.Longitude, y = Start.Latitude),
             color = "black", fill = "red", size = 3, shape = 21) + # Add start points of transects
  annotation_scale(location = "bl", width_hint = 0.5) +
  annotation_north_arrow(location = "bl", which_north = "true", 
                         pad_x = unit(0.5, "in"), pad_y = unit(0.2, "in"),
                         style = north_arrow_fancy_orienteering) +
    geom_text(data = labels, aes(x = lon, y = lat, label = name), size = 5, color = "black") + # Add labels
  # Change x and y axes names
  labs(x = "Longitude", y = "Latitude") +
  theme_classic() + # Remove axes and background
  xlim(c(-71.40, -71.35)) + # Set longitude range
  ylim(c(41.46, 41.5))   # Set latitude range


panelB

# Save the plot to a file
ggsave("output/figures/figure_1B.png", plot = panelB, width = 8, height = 8)


# Filter transect data by site
transect_kb <- filter(site, Site == "King's Beach")

# Define label data
labels_kb <- data.frame(
  name = c("King's\nBeach"),
  lat = c(41.463),
  lon = c(-71.33)
)

# Adjust latitude values by subtracting 0.0011
transect_kb <- transect_kb %>%
  mutate(
    Start.Latitude = Start.Latitude - 0.0003
  )

# Plot panel C for kings beach transects
panelC <- ggplot() +
  geom_sf(data = ri_state, fill = "lightgray") + # State boundaries
  geom_point(data = transect_kb,
             aes(x = Start.Longitude, y = Start.Latitude),
             color = "black", fill = "red", size = 3, shape = 21) + # Add start points of transects
  annotation_scale(location = "bl", width_hint = 0.5) +
  annotation_north_arrow(location = "bl", which_north = "true", 
                         pad_x = unit(0.6, "in"), pad_y = unit(0.2, "in"),
                         style = north_arrow_fancy_orienteering) +
    geom_text(data = labels_kb, aes(x = lon, y = lat, label = name), size = 5, color = "black") + # Add labels
  # Change x and y axes names
  labs(x = "Longitude", y = "Latitude") +
  theme_classic() + # Remove axes and background
  xlim(c(-71.40, -71.3)) + # Set longitude range
  ylim(c(41.44, 41.5))   # Set latitude range


panelC

# Save the plot to a file
ggsave("output/figures/figure_1C.png", plot = panelC, width = 8, height = 6)


```

# Plot all three panels together using patchwork
```{r}

# Adjust width for individual plots
panelB <- panelB + theme(plot.margin = margin(r = 0))  # Remove right margin
panelC <- panelC + theme(plot.margin = margin(l = 0))  # Remove left margin

# Combine the plots with patchwork
combined_plot <- (panelA | (panelB / panelC)) +
  plot_annotation(tag_levels = 'A') + 
  theme(plot.tag = element_text(size = 20, face = "bold"));combined_plot

# Save the combined plot
ggsave("output/figures/figure_1.png", combined_plot, width = 12, height = 8, units = "in", dpi = 300)

```


# Figure 2: organize data to make fish biomass (g/m2) on y-axis and Kelp cover (%) figure
```{r}
# take kelp cover long and just extract data for sugar kelp 2019-2023
kelp.filt <- kelp %>%
        filter(SP_CODE == "SUGK")

# Convert the integer column to character
kelp.filt$CONTROL <- as.character(kelp.filt$CONTROL)
kelp.filt$TRANSECT <- as.character(kelp.filt$TRANSECT)

# remove control column, not needed
kelp.filt <- kelp.filt[ -c(5) ]

# Read the fish aggregated CSV file 2019-2023 and skip the first column
fish <- read.csv("data/kelp_timeseries_data/fish_Aggregated.csv") %>%
          select(-1)

# Remove "KB", "FW", and space, keep only numbers
fish.filt <- fish %>%
  mutate(TRANSECT = gsub("KB |FW ", "", TRANSECT))

# Convert the integer column to character
fish.filt$TRANSECT <- as.character(fish.filt$TRANSECT)

# Rename fort weatherill
fish.filt$SITE[fish.filt$SITE == "Kings Beach"] <- "King's Beach"

# remove control column, not needed
fish.filt <- fish.filt[ -c(5) ]

# Assuming you want to join by the 'transect' column
merged.dat.cover <- left_join(fish.filt, kelp.filt)


```


# Make Figure 2 and run statistical analysis
```{r}
# Aggregate the data by year, site, and transect and compute mean values
aggregated_data_cover <- merged.dat.cover %>%
  group_by(YEAR, SITE, TRANSECT) %>%
  summarize(mean_fish_biomass = mean(Fish.Biomass..g.m2., na.rm = TRUE),
            mean_kelp_cover = mean(COVER, na.rm = TRUE)) %>%
  ungroup()

# Filter dataframe for six top fish biomass above 150
filt_data <- aggregated_data_cover %>%
  filter(mean_fish_biomass > 150)

# Make biomass a percent so * 100
aggregated_data_cover$mean_kelp_cover <- aggregated_data_cover$mean_kelp_cover * 100

# Fit the linear mixed effects model
lmm_model <- lmer(mean_fish_biomass ~ mean_kelp_cover + SITE + (1 | SITE/YEAR), data = aggregated_data_cover)
#check normality
qqPlot(residuals(lmm_model)) #slightly non normal values, log transform to improve

# Fit the linear mixed effects model with log transformation
lmm_model <- lmer(log(mean_fish_biomass) ~ mean_kelp_cover + SITE + (1 | SITE/YEAR), data = aggregated_data_cover)
#check normality
qqPlot(residuals(lmm_model)) #improved to normal

# Summarize the model
lmm_summary <- summary(lmm_model)
lmm_tidy <- tidy(lmm_model)

# Calculate R-squared for the mixed model
r_squared <- r.squaredGLMM(lmm_model)

# Extract marginal and conditional R-squared
marginal_r2 <- round(r_squared[1], 2)
conditional_r2 <- round(r_squared[2], 2)

# Extract p-value for mean_kelp_cover
p_value_kelp_cover <- summary(lmm_model)$coefficients["mean_kelp_cover", "Pr(>|t|)"]

# Create scatter plot
figure.2 <- ggplot(aggregated_data_cover, aes(x = log(mean_kelp_cover), y = log(mean_fish_biomass))) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, formula = y ~ x, color = "blue") +
annotate("text", x = Inf, y = Inf, label = paste0("Marginal R^2 = ", marginal_r2, "\nConditional R^2 = ", conditional_r2, "\np = ", signif(p_value_kelp_cover, 3)), hjust = 1.4, vjust = 1.1, size = 4, parse = FALSE) + # Adjust vjust
  labs(x = "Log Kelp cover (%)", y = "Log Fish biomass (g/m2)",
       title = "Fish Biomass vs Kelp Cover") +
  theme_classic();figure.2

# Save the plot to a file
ggsave("output/figures/figure_2.png", plot = figure.2, width = 8, height = 6)
```


# Figure 3: organize and calculate kelp biomass data to make fish biomass/kelp biomass (g/m2) linear regression figure
```{r}
# read in quad data with filtered for just kelp
quad.filt <- QUAD %>%
        filter(SP_CODE == "SUGK")

# remove control column and two last columns, not needed
quad.filt <- quad.filt[ -c(13:14) ] 
quad.filt <- quad.filt[ -c(8) ] 
quad.filt <- quad.filt[ -c(5:6) ] 

# I noticed that 06/30/23 dates were accidentily labeled 06/30/29
# Replace "29" with "23" in the DATE column
quad.filt$DATE <- sub("29$", "23", quad.filt$DATE)

# Convert DATE to Date format
quad.filt$DATE <- as.Date(quad.filt$DATE, format = "%m/%d/%y")

# Convert Date format to "YYYY-MM-DD"
quad.filt$DATE <- format(quad.filt$DATE, "%Y-%m-%d")

# combine quad data with morph data to calculate kelp biomass

#load in morph data and select for SUGK
morph.filt <- morph %>%
        filter(SP_CODE == "SL")

#rename SL to SUGK
morph.filt$SP_CODE[morph.filt$SP_CODE == "SL"] <- "SUGK"

# Convert the integer column to character
morph.filt$TRANSECT <- as.character(morph.filt$TRANSECT)

# merge morph filt and quad.filt to calculate biomass
merge.morph.quad <- left_join(morph.filt, quad.filt)

#calculate kelp biomass
# To get wet weight in grams (biomass) you use the equation: y=0.00421*x^1.951 where x is kelp blade + stipe length.
# Calculate the sum of blade length and stipe length
merge.morph.quad$sum_length <- merge.morph.quad$BLADE_LENGTH_CM + merge.morph.quad$STIPE_LENGTH_CM

# Define a function to calculate kelp biomass
calculate_kelp_biomass <- function(x) {
  y <- 0.00421 * x^1.951
  return(y)
}

# Calculate kelp biomass using the sum of blade length and stipe length
merge.morph.quad$kelp_biomass <- calculate_kelp_biomass(merge.morph.quad$sum_length)

# Remove the intermediate columns if no longer needed
merge.morph.quad$kelp_blade_length <- NULL
merge.morph.quad$sum_length <- NULL

# Replace NA values with 0
merge.morph.quad$kelp_biomass <- ifelse(is.na(merge.morph.quad$kelp_biomass), 0, merge.morph.quad$kelp_biomass)

# Sum kelp biomass at the transect level
morph.filt <- merge.morph.quad %>%
  group_by(TRANSECT, YEAR, SITE) %>%
  summarize(total_kelp_biomass = sum(kelp_biomass))

# Divide by 6 quadrats for correct g/m2 calculation
morph.filt$average_kelp_biomass <- morph.filt$total_kelp_biomass / 6

# Merge fish and morph data
merged.dat.morph <- left_join(morph.filt, fish.filt)

```


# Make figure 3 and run statistical analysis
```{r}
# Aggregate the data by year, site, and transect and compute mean values
aggregated.data.morph <- merged.dat.morph %>%
  group_by(YEAR, SITE, TRANSECT) %>%
  summarize(mean_fish_biomass = mean(Fish.Biomass..g.m2., na.rm = TRUE),
            mean_kelp_biomass = mean(average_kelp_biomass, na.rm = TRUE)) %>%
  ungroup()

# Fit the linear mixed effects model
lmm_model <- lmer(mean_fish_biomass ~ mean_kelp_biomass + SITE + (1 | SITE/YEAR), data = aggregated.data.morph)
#check normality
qqPlot(residuals(lmm_model)) #slightly non normal values, log transform to improve

# Fit the linear mixed effects model with log transformation
lmm_model <- lmer(log(mean_fish_biomass) ~ mean_kelp_biomass + SITE + (1 | SITE/YEAR), data = aggregated.data.morph)
#check normality
qqPlot(residuals(lmm_model)) #improved to normal

# Summarize the model
lmm_summary <- summary(lmm_model)
lmm_tidy <- tidy(lmm_model)

# Calculate R-squared for the mixed model
r_squared <- r.squaredGLMM(lmm_model)

# Extract marginal and conditional R-squared
marginal_r2 <- round(r_squared[1], 2)
conditional_r2 <- round(r_squared[2], 2)

# Extract p-value for mean_kelp_cover
p_value_kelp_biomass <- summary(lmm_model)$coefficients["mean_kelp_biomass", "Pr(>|t|)"]

# Create scatter plot
figure.3 <- ggplot(aggregated.data.morph, aes(x = log(mean_kelp_biomass), y = log(mean_fish_biomass))) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, formula = y ~ x, color = "blue") +
annotate("text", x = Inf, y = Inf, label = paste0("Marginal R^2 = ", marginal_r2, "\nConditional R^2 = ", conditional_r2, "\np = ", signif(p_value_kelp_biomass, 3)), hjust = 1.4, vjust = 1.1, size = 4, parse = FALSE) + # Adjust vjust
  labs(x = "Log Kelp Biomass (g/m2)", y = "Log Fish biomass (g/m2)",
       title = "Fish Biomass vs Kelp Biomass") +
  theme_classic();figure.3

# Save the plot to a file
ggsave("output/figures/figure_3.png", plot = figure.3, width = 8, height = 6)
```


# Figure 4: organize rugosity data and make linear regression figure for fish biomass and rugosity
```{r}
# Calculate mean rugosity complexity scores across depths for each transect, grouped by site and year
mean_rugosity <- rugosity %>%
  group_by(SITE, YEAR, TRANSECT) %>%
  summarize(mean_rugosity = mean(c(X0M, X4M, X8M, X12M, X16M, X20M, X24M, X28M, X32M, X36M, X40M), na.rm = TRUE))

# edited control transcet name
mean_rugosity$TRANSECT[mean_rugosity$TRANSECT == "Control 2"] <- "2"

# change transect from integer to chr
mean_rugosity$TRANSECT <- as.character(mean_rugosity$TRANSECT)

# Left jon fish and rugosity data
merged.dat.rug <- left_join(mean_rugosity, fish.filt)

```


# Make figure 4 and run statistical analysis
```{r}
# Aggregate the data by year, site, and transect and compute mean values
aggregated.data.rug <- merged.dat.rug %>%
  group_by(YEAR, SITE, TRANSECT) %>%
  summarize(mean_fish_biomass = mean(Fish.Biomass..g.m2., na.rm = TRUE),
            mean_rugosity = mean(mean_rugosity, na.rm = TRUE)) %>%
  ungroup()

# Fit the linear mixed effects model
lmm_model <- lmer(mean_fish_biomass ~ mean_rugosity + SITE + (1 | SITE/YEAR), data = aggregated.data.rug)
#check normality
qqPlot(residuals(lmm_model)) #data is normal no need to transform

# Summarize the model
lmm_summary <- summary(lmm_model)
lmm_tidy <- tidy(lmm_model)

# Calculate R-squared for the mixed model
r_squared <- r.squaredGLMM(lmm_model)

# Extract marginal and conditional R-squared
marginal_r2 <- round(r_squared[1], 2)
conditional_r2 <- round(r_squared[2], 2)

# Extract p-value for mean_kelp_cover
p_value_rugosity <- summary(lmm_model)$coefficients["mean_rugosity", "Pr(>|t|)"]

# Create scatter plot
figure.4 <- ggplot(aggregated.data.rug, aes(x = mean_rugosity, y = mean_fish_biomass)) +
  geom_point() +
  geom_smooth(method = "lm", se = TRUE, formula = y ~ x, color = "blue") +
  annotate("text", x = Inf, y = Inf, label = paste0("Marginal R^2 = ", marginal_r2, "\nConditional R^2 = ", conditional_r2, "\np = ", signif(p_value_rugosity, 2)), 
           hjust = 2.1, vjust = 1.1, size = 4, parse = FALSE) +
  labs(x = "Rugosity Complexity", y = "Fish biomass (g/m2)",
       title = "Fish Biomass vs Rugosity Complexity") +
  theme_classic();figure.4

# Save the plot to a file
ggsave("output/figures/figure_4.png", plot = figure.4, width = 8, height = 6)
```


# Filter quad data for all inverts and use to correlate to fish biomass
```{r}




 
```








# Figure 5: Correlation analysis between fish biomass (g/m2), kelp biomass (g/m2), kelp cover, rugosity, temperature in ggplot 
# combine all dataframes
```{r}
# left join can only combine two at a time
# combing kelp cover and fish biomass
master.dat1 <- left_join(kelp.filt, fish.filt)

#combine rugosity and kelp biomass
master.dat2 <- left_join(mean_rugosity, morph.filt)

# combine for final dataframe
master.dat <- left_join(master.dat1, master.dat2)

#select necessary columns
all.params.data <- master.dat %>% select("YEAR", "SITE", "COVER", "Fish.Biomass..g.m2.", "mean_rugosity", "average_kelp_biomass")

#rename various columns in data frame
names(all.params.data)[3] <- "Kelp Cover (%)"
names(all.params.data)[4] <- "Fish Biomass (g/cm2)"
names(all.params.data)[5] <- "Rugosity"
names(all.params.data)[6] <- "Kelp Biomass (g/cm2)"

#reorder columns to show biomass by eachother
all.params.data <- all.params.data[, c(1,2, 4, 6, 5, 3)]

view(all.params.data)

# Check for missing values
any_missing <- any(is.na(all.params.data))
if (any_missing) {
  # Handle missing values
  all.params.data <- na.omit(all.params.data)
}

# Select the relevant columns
selected_columns <- all.params.data[, c("Fish Biomass (g/cm2)", "Kelp Biomass (g/cm2)", "Rugosity", "Kelp Cover (%)")]

# Calculate the Spearman correlation matrix
cormat <- round(cor(selected_columns, method = "spearman", use = "complete.obs"), 4)
head(cormat)

#melt the correlation matrix means it reassembles data frame to be more effective to complete corr matrix
#to long format
melted_cormat <- melt(cormat)
head(melted_cormat)

#visulaize the correlation matrix in general
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile()

# Get lower and upper triangle of the correlation matrix
#Note that, a correlation matrix has redundant information. We’ll use the functions below to set half of it to NA
get_lower_tri<-function(cormat){
  cormat[upper.tri(cormat)] <- NA
  return(cormat)
}
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cormat){
  cormat[lower.tri(cormat)]<- NA
  return(cormat)
}

#apply upper tri calculation to graphc
upper_tri <- get_upper_tri(cormat)
upper_tri

#melt the correlation matrix
#melt the correlation data and drop the rows with NA values 
melted_cormat <- melt(upper_tri, na.rm = TRUE)

#heatmap of correlation matrix
#negative correlations are in purple color and positive correlations in red
#scale_fill_gradient2 is used with the argument limit = c(-1,1) as correlation coefficients range from -1 to 1
#coord_fixed() : this function ensures that one unit on the x-axis is the same length as one unit on the y-axis
ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
  geom_tile(color = "white")+
  scale_fill_gradient2(low = "midnightblue", high = "firebrick4", mid = "white", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman's\nCorrelation") +
  theme_minimal()+ 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1))+
  coord_fixed()



#edit the number of sig figs listed in the value column
melted_cormat <- melted_cormat %>% mutate_at(vars(starts_with("value")), funs(round(., 2)))

# Create a ggheatmap with basic characteristics, etc. 
ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
  geom_tile(color = "white")+
  scale_fill_gradient2(low = "firebrick3", mid = "white", high = "dodgerblue3", 
                       midpoint = 0, limit = c(-1,1), space = "Lab", 
                       name="Spearman's\nCorrelation") +
  theme_minimal()+ # minimal theme
  theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                   size = 12, hjust = 1))+
  coord_fixed()


# Print the heatmap
print(ggheatmap)


# Check for normality
shapiro.test(all.params.data$`Kelp Cover (%)`)
shapiro.test(all.params.data$`Fish Biomass (g/cm2)`) 
shapiro.test(all.params.data$Rugosity)
shapiro.test(all.params.data$`Kelp Biomass (g/cm2)`)

# data is not normal so move forward using aa spearmans rank correlation test

## Calculate p-values
p_values <- cor.mtest(selected_columns, method = "spearman")$p

## Convert the correlation matrix to a data frame
cormat_df <- reshape2::melt(cormat)

## Add p-values to the data frame
cormat_df$p_value <- p_values[cbind(cormat_df$Var1, cormat_df$Var2)]

# Define the custom apply_rules function
apply_rules <- function(p_values, rules = c(0.001, 0.01, 0.05), symbols = c("***", "**", "*")) {
  result <- rep("", length(p_values))
  for (i in seq_along(rules)) {
    result[p_values < rules[i]] <- symbols[i]
  }
  return(result)
}

## Create a new column to display stars based on p-values
cormat_df$sig <- apply_rules(cormat_df$p_value, rules = c(0.001, 0.01, 0.05), symbols = c("***", "**", "*"))

# Remove repeating rows
corузыdated_cormat_df <- cormat_df[!duplicated(cormat_df[, c("Var1", "Var2")]), ]

# Replace non-significant p-узыdues with "ns"
cormat_df$sig[cormat_df$p_value > 0.05] <- "ns"

# Print the modified data
print(cormat_df)

# Add correlation coefficients to the heatmap
ggheatmap +
  geom_text(data = cormat_df, aes(Var1, Var2, label = ifelse(Var1 == Var2, value, 
                                                             ifelse(sig == "", paste0(value, "\nns"), 
                                                             ifelse(duplicated(paste0(value, "\n", sig)), "", paste0(value, "\n", sig))))), 
            color = "black", size = 6) +
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.text.x = element_text(size = 18, face="bold", color="black"),
        axis.text.y = element_text(size = 18, face="bold", color="black"),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.ticks = element_blank(),
        legend.justification = c(0.8, 0),
        legend.title = element_text(size = 18, face="bold", color="black"),
        legend.text = element_text(size = 20, face="bold", color="black"),
        legend.position = c(0.48, 0.75),
        legend.direction = "horizontal") +
  guides(fill = guide_colorbar(barwidth = 12, barheight = 2,
                               title.position = "top", title.hjust = 0.5, title.vjust = 1.0))



ggsave(filename = "output/figures/correlation_analysis_figure.png", device = "png", width = 10, height = 10)


```

# Figure 5: Multiple regression between fish biomass (g/m2), kelp biomass (g/m2), kelp cover, rugosity, temperature in ggplot 
# combine all dataframes
```{r}
# Rename columns to remove spaces and special characters
names(all.params.data) <- c("YEAR", "SITE", "Fish_Biomass", "Rugosity", "Kelp_Cover", "Kelp_Biomass")

# was getting an error: qr.default(X, tol = tol, LAPACK = FALSE) when running model below which indicates that there are still problematic values (NA, NaN, or Inf) in the data used for the model fitting

# Check for zero or negative values
zero_or_negative <- sapply(all.params.data[, c("Fish_Biomass", "Rugosity", "Kelp_Biomass", "Kelp_Cover")], function(x) sum(x <= 0))
zero_or_negative

# Remove rows with zero or negative values in relevant columns
all.params.data <- all.params.data[all.params.data$Fish_Biomass > 0 & 
                                   all.params.data$Rugosity > 0 & 
                                   all.params.data$Kelp_Biomass > 0 & 
                                   all.params.data$Kelp_Cover > 0, ]

# Fit a multiple regression model
fit1 <- lm(log(Fish_Biomass) ~ log(Rugosity) * log(Kelp_Biomass) * log(Kelp_Cover), data = all.params.data)

# Diagnostic plots for the regression model
par(mfrow=c(2,2))
plot(fit1)

# Produce added multivariable plots
av_plots <- avPlots(fit1)

#The x-axis displays a single predictor variable and the y-axis displays the response variable.
#The blue line shows the association between the predictor variable and the response variable, while holding the value of all other predictor variables constant.
#The points that are labelled in each plot represent the 2 observations with the largest residuals and the 2 observations with the largest partial leverage.

#view results of model
summary_text1 <- capture.output(summary(fit1))
writeLines(summary_text1, "output/figures/summary_original.model.txt")

```


# Try another type of multiple regession plot
```{r}
#fit multiple linear regression model WITH SITE AND YEAR
fit2 <- lm(Fish_Biomass ~ SITE*YEAR, data = all.params.data)

#view results of model
summary_text2 <- capture.output(summary(fit2))
writeLines(summary_text2, "output/figures/summary_model_site_year_fixed_fishbiomass.txt")


# Fit the mixed-effects model
fit3 <- lmer(log(Fish_Biomass) ~ log(Rugosity) * log(Kelp_Biomass) * log(Kelp_Cover) + 
              (1 | SITE) + (1 | YEAR), data = all.params.data)

#view results of model
summary_text3 <- capture.output(summary(fit3))
writeLines(summary_text3, "output/figures/summary_model_site_year_random.txt")

# site and year no significant interaction or significant main effects

# run with just site as random effect
# Fit the mixed-effects model
fit4 <- lmer(log(Fish_Biomass) ~ log(Rugosity) * log(Kelp_Biomass) * log(Kelp_Cover) + 
              (1 | SITE), data = all.params.data)

#view results of model
summary_text4 <- capture.output(summary(fit4))
writeLines(summary_text4, "output/figures/summary_model_site_random.txt")

# site and year no significant main effects

# run with just year as random effect
# Fit the mixed-effects model
fit5 <- lmer(log(Fish_Biomass) ~ log(Rugosity) * log(Kelp_Biomass) * log(Kelp_Cover) + 
              (1 | YEAR), data = all.params.data)

#view results of model
summary_text5 <- capture.output(summary(fit5))
writeLines(summary_text5, "output/figures/summary_model_year_random.txt")

#year is significantly different for kelp cover

```

